{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import csv\n",
    "import signal\n",
    "import subprocess\n",
    "import argparse\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# Configure graphs to skip (without .edge suffix)\n",
    "SKIP_LIST = {\n",
    "    'Paley17',\n",
    "}\n",
    "\n",
    "\n",
    "def apex_vertices(g):\n",
    "    \"\"\"\n",
    "    Remove apex vertices (degree == n-1), return (reduced_graph, count_removed).\n",
    "    \"\"\"\n",
    "    to_remove = [u for u, d in g.degree() if d == g.number_of_nodes() - 1]\n",
    "    g.remove_nodes_from(to_remove)\n",
    "    buff = len(to_remove)\n",
    "    g = nx.convert_node_labels_to_integers(g, first_label=0, ordering=\"default\")\n",
    "    return g, buff\n",
    "\n",
    "\n",
    "def degree_one_reduction(g):\n",
    "    \"\"\"\n",
    "    Remove all but one degree‐1 neighbor per vertex.\n",
    "    \"\"\"\n",
    "    to_remove = set()\n",
    "    for u in g.nodes():\n",
    "        seen = False\n",
    "        for v in g.neighbors(u):\n",
    "            if g.degree(v) == 1:\n",
    "                if not seen:\n",
    "                    seen = True\n",
    "                else:\n",
    "                    to_remove.add(v)\n",
    "    g.remove_nodes_from(to_remove)\n",
    "    return nx.convert_node_labels_to_integers(g, first_label=0, ordering=\"default\")\n",
    "\n",
    "\n",
    "def read_edge(filename):\n",
    "    \"\"\"\n",
    "    Read a .edge file: skip to 'p ' line, parse number of edges,\n",
    "    then read that many lines starting with 'e '.\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines = [l.strip() for l in f if l.strip()]\n",
    "    p_idx = next(i for i, l in enumerate(lines) if l.startswith('p '))\n",
    "    m = int(lines[p_idx].split()[-1])\n",
    "    edges = []\n",
    "    for l in lines[p_idx+1 : p_idx+1+m]:\n",
    "        if not l.startswith('e '):\n",
    "            continue\n",
    "        _, a, b, *_ = l.split()\n",
    "        edges.append((int(a), int(b)))\n",
    "    if len(edges) < m:\n",
    "        for l in lines[p_idx+1+m:]:\n",
    "            if l.startswith('e '):\n",
    "                _, a, b, *_ = l.split()\n",
    "                edges.append((int(a), int(b)))\n",
    "                if len(edges) >= m:\n",
    "                    break\n",
    "    return edges\n",
    "\n",
    "\n",
    "def make_vars(g, width):\n",
    "    nv = g.number_of_nodes()\n",
    "    p = [[[0]*width for _ in range(nv)] for __ in range(nv)]\n",
    "    cur = 1\n",
    "    for u in range(nv):\n",
    "        for v in range(u, nv):\n",
    "            for i in range(width):\n",
    "                p[u][v][i] = cur\n",
    "                cur += 1\n",
    "    return p, cur-1\n",
    "\n",
    "\n",
    "def generate_encoding(g, width):\n",
    "    \"\"\"\n",
    "    Build CNF encoding string for treedepth ≤ width.\n",
    "    \"\"\"\n",
    "    s, nvar = make_vars(g, width)\n",
    "    clauses = []\n",
    "    nv = g.number_of_nodes()\n",
    "    nclauses = 0\n",
    "\n",
    "    # 1) each pair has some depth\n",
    "    for u in range(nv):\n",
    "        for v in range(u, nv):\n",
    "            clauses.append(f\"{s[u][v][width-1]} 0\"); nclauses += 1\n",
    "            clauses.append(f\"-{s[u][v][0]} 0\");        nclauses += 1\n",
    "\n",
    "    # 2) monotonicity\n",
    "    for u in range(nv):\n",
    "        for v in range(u, nv):\n",
    "            for i in range(1, width):\n",
    "                clauses.append(f\"-{s[u][v][i-1]} {s[u][v][i]} 0\"); nclauses += 1\n",
    "\n",
    "    # 3) transitivity\n",
    "    for u in range(nv):\n",
    "        for v in range(u+1, nv):\n",
    "            for w in range(v+1, nv):\n",
    "                for i in range(width):\n",
    "                    clauses.append(f\"-{s[u][v][i]} -{s[u][w][i]} {s[v][w][i]} 0\")\n",
    "                    clauses.append(f\"-{s[u][v][i]} -{s[v][w][i]} {s[u][w][i]} 0\")\n",
    "                    clauses.append(f\"-{s[u][w][i]} -{s[v][w][i]} {s[u][v][i]} 0\")\n",
    "                    nclauses += 3\n",
    "\n",
    "    # 4) pair ⇒ vertices\n",
    "    for u in range(nv):\n",
    "        for v in range(u+1, nv):\n",
    "            for i in range(width):\n",
    "                clauses.append(f\"-{s[u][v][i]} {s[u][u][i]} 0\")\n",
    "                clauses.append(f\"-{s[u][v][i]} {s[v][v][i]} 0\")\n",
    "                nclauses += 2\n",
    "\n",
    "    # 5) root ancestors\n",
    "    for u in range(nv):\n",
    "        for v in range(u+1, nv):\n",
    "            for i in range(1, width):\n",
    "                clauses.append(f\"-{s[u][v][i]} {s[u][u][i-1]} {s[v][v][i-1]} 0\"); nclauses += 1\n",
    "\n",
    "    # 6) edges ⇒ connectivity\n",
    "    for (u, v) in g.edges():\n",
    "        if u > v: u, v = v, u\n",
    "        for i in range(1, width):\n",
    "            clauses.append(f\"-{s[u][u][i]} {s[u][u][i-1]} -{s[v][v][i]} {s[u][v][i]} 0\")\n",
    "            clauses.append(f\"-{s[u][u][i]} {s[v][v][i-1]} -{s[v][v][i]} {s[u][v][i]} 0\")\n",
    "            nclauses += 2\n",
    "\n",
    "    preamble = f\"p cnf {nvar} {nclauses}\"\n",
    "    return preamble + \"\\n\" + \"\\n\".join(clauses) + \"\\n\"\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, time_list=None):\n",
    "        self.time_list = time_list\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        dur = time.time() - self.start\n",
    "        if self.time_list is not None:\n",
    "            self.time_list.append(dur)\n",
    "\n",
    "\n",
    "def solve_component(g, cli_args):\n",
    "    \"\"\"\n",
    "    Use original paper logic: search width descending from n+1 to 2,\n",
    "    return at first rc == 20 (SAT) as in the paper code.\n",
    "    \"\"\"\n",
    "    encoding_times = []\n",
    "    solving_times = []\n",
    "    lb = ub = 0\n",
    "    to = False\n",
    "    n = g.number_of_nodes()\n",
    "    if n <= 1:\n",
    "        return n, n, n, False, encoding_times, solving_times\n",
    "\n",
    "    temp = os.path.abspath(cli_args.temp)\n",
    "    inst = cli_args.instance\n",
    "    # descending search\n",
    "    for w in range(n+1, 1, -1):\n",
    "        with Timer(time_list=encoding_times):\n",
    "            cnf_str = generate_encoding(g, w)\n",
    "            cnf_file = os.path.join(temp, f\"{inst}_{w}.cnf\")\n",
    "            with open(cnf_file, 'w') as f:\n",
    "                f.write(cnf_str)\n",
    "\n",
    "        sol_file = os.path.join(temp, f\"{inst}_{w}.sol\")\n",
    "        cmd = [cli_args.solver, f\"-cpu-lim={cli_args.timeout}\", cnf_file, sol_file]\n",
    "        with Timer(time_list=solving_times):\n",
    "            p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            p.communicate()\n",
    "            rc = p.returncode\n",
    "\n",
    "        if rc == 0:\n",
    "            to = True\n",
    "            if lb == ub == 0:\n",
    "                ub = w\n",
    "        elif rc == 20:\n",
    "            if to:\n",
    "                lb = w\n",
    "            if lb == ub == 0:\n",
    "                lb = ub = w\n",
    "            return w, lb, ub, to, encoding_times, solving_times\n",
    "\n",
    "    return 1, lb, ub, to, encoding_times, solving_times\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Batch-run treedepthp2sat\")\n",
    "    parser.add_argument('--solver',  type=str, default='glucose', help='SAT solver')\n",
    "    parser.add_argument('--timeout', type=int, default=900,      help='timeout per SAT (s)')\n",
    "    parser.add_argument('--temp',    type=str, default=os.path.join(os.getcwd(), 'temp'),\n",
    "                        help='temp dir')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def batch_run(cli_args):\n",
    "    os.makedirs(cli_args.temp, exist_ok=True)\n",
    "\n",
    "    # collect graphs\n",
    "    tasks = []\n",
    "    for ds in ['famous', 'standard']:\n",
    "        for fn in glob.glob(os.path.join('inputs', ds, '*.edge')):\n",
    "            tasks.append((ds, fn))\n",
    "    total = len(tasks)\n",
    "    print(f\"Found {total} graphs in total, starting batch processing...\")\n",
    "\n",
    "    with open('resultsat.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            'dataset','instance',\n",
    "            'n_original','m_original',\n",
    "            'n_reduced','buff',\n",
    "            'td_lb','td_ub',\n",
    "            'total_time_s',\n",
    "            'sum_encoding_s','sum_solving_s'\n",
    "        ])\n",
    "\n",
    "        for idx, (ds, fn) in enumerate(tasks, start=1):\n",
    "            inst = os.path.splitext(os.path.basename(fn))[0]\n",
    "            # blacklist\n",
    "            if inst in SKIP_LIST:\n",
    "                print(f\"[{idx}/{total}] ({ds}) Skipping {inst} (blacklisted)\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[{idx}/{total}] ({ds}) Processing {inst} ...\", end='', flush=True)\n",
    "\n",
    "            edges = read_edge(fn)\n",
    "            g0 = nx.Graph(); g0.add_edges_from(edges)\n",
    "            n0, m0 = g0.number_of_nodes(), g0.number_of_edges()\n",
    "\n",
    "            # skip large\n",
    "            if n0 > 20:\n",
    "                print(f\" Skipped, vertex count {n0} > 20\")\n",
    "                continue\n",
    "\n",
    "            t0 = time.time()\n",
    "            g1 = degree_one_reduction(g0.copy())\n",
    "            g2, buff = apex_vertices(g1)\n",
    "\n",
    "            td_lb, td_ub = float('inf'), -1\n",
    "            all_enc, all_sol = [], []\n",
    "            for comp in nx.connected_components(g2):\n",
    "                sub = g2.subgraph(comp).copy()\n",
    "                sub = nx.convert_node_labels_to_integers(sub, first_label=0, ordering=\"default\")\n",
    "                cli_args.instance = inst\n",
    "                w, lb, ub, to, et, st = solve_component(sub, cli_args)\n",
    "                td_lb = min(td_lb, lb)\n",
    "                td_ub = max(td_ub, ub)\n",
    "                all_enc.extend(et)\n",
    "                all_sol.extend(st)\n",
    "\n",
    "            # add back apex buffer\n",
    "            td_lb += buff\n",
    "            td_ub += buff\n",
    "\n",
    "            total_time = time.time() - t0\n",
    "            writer.writerow([\n",
    "                ds, inst,\n",
    "                n0, m0,\n",
    "                g2.number_of_nodes(), buff,\n",
    "                td_lb, td_ub,\n",
    "                f\"{total_time:.2f}\",\n",
    "                f\"{sum(all_enc):.2f}\", f\"{sum(all_sol):.2f}\"\n",
    "            ])\n",
    "            print(f\" Completed, td=[{td_lb}-{td_ub}], time {total_time:.2f}s\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    if hasattr(signal, 'SIGHUP'):\n",
    "        signal.signal(signal.SIGHUP, lambda s,f: sys.exit(0))\n",
    "    args = parse_args()\n",
    "    batch_run(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
